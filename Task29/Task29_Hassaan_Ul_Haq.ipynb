{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5b9b681-8d7c-4a31-86d1-29d060023acb",
   "metadata": {},
   "source": [
    "# Task29-> Hyperparameter Tuning Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2d0aa5-410f-4187-927a-4f193778199c",
   "metadata": {},
   "source": [
    "### \n",
    "When working on a machine learning project, selecting and fine-tuning the right model is essential for \n",
    "optimal performance. Common models from sklearn include Linear Regression for predicting continuous \n",
    "values, Logistic Regression for binary classification, and Decision Trees, Random Forests, SVMs, and\n",
    "KNNs for various classification and regression tasks. Hyperparameter tuning techniques such as Grid \n",
    "Search, Random Search, and Bayesian Optimization can be employed to find the best parameters for these \n",
    "models, enhancing their performance and predictive accuracy. Apply these techniques and note down the\n",
    "results to evaluate the impact of different models and hyperparameters on your dataset's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53ad4fd-7cc3-4cec-b7c0-5f6862745e17",
   "metadata": {},
   "source": [
    "### importing necessary libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40dd83df-2a9e-4031-a47a-f400d238bc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "file_path = r'C:\\Users\\Huawei\\Desktop\\Iris.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f844e66-b3e0-4d18-9bb2-762d857a1484",
   "metadata": {},
   "source": [
    "### Map species to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f497594a-6eaf-49ee-b0af-a92f0a6a0d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_mapping = {'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2}\n",
    "df['Species'] = df['Species'].map(species_mapping)#converted categorical labels into numerical values so that models can process and analyze the data effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dbcf21-901f-4583-8b81-a096ee6b79b4",
   "metadata": {},
   "source": [
    "### Define features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dda2987c-4f4c-43a5-93c9-4b8de5ccdc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]\n",
    "y = df['Species']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7194a034-15ba-4577-b280-8b39294be048",
   "metadata": {},
   "source": [
    "### Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f8a6f52-1737-4e7c-8c44-09391153dca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4141ba73-e2af-47d2-8b80-97192762c07b",
   "metadata": {},
   "source": [
    "### Define models and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc82ee85-1b16-40bb-9fed-72fc2f6c16bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': {\n",
    "        'model': LogisticRegression(),\n",
    "        'params': {'C': [0.1, 1, 10], 'solver': ['lbfgs', 'liblinear']}#C represent regularization(to prevent overfitting) , solver is holding a list of optimzation algorithms lbfgs and liblinear.\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'model': DecisionTreeClassifier(),\n",
    "        'params': {'max_depth': [3, 5, 7]}\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params': {'n_estimators': [10, 50, 100], 'max_features': ['auto', 'sqrt']}#auto for total no. of features, sqrt for square root of total no. of features. \n",
    "    },\n",
    "    'SVM': {\n",
    "        'model': SVC(),\n",
    "        'params': {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}#here kernel is holding a list of kernel types linear and rbf.\n",
    "    },\n",
    "    'KNN': {\n",
    "        'model': KNeighborsClassifier(),\n",
    "        'params': {'n_neighbors': [3, 5, 7]}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca7d597-4364-4cfc-b079-553197ebba75",
   "metadata": {},
   "source": [
    "### Perform Grid Search for classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "228d5e24-f6e1-4323-bbac-f169bcc70bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Huawei\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Huawei\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Huawei\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Huawei\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Huawei\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Huawei\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Huawei\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Huawei\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Huawei\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Huawei\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Huawei\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Huawei\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Huawei\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Huawei\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Huawei\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Huawei\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Huawei\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Huawei\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Huawei\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Huawei\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Huawei\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "for name, model_info in models.items():\n",
    "    clf = GridSearchCV(model_info['model'], model_info['params'], cv=5)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf28bf5-ebbf-4173-ad7e-30af67ae5b67",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "035cc03c-4e31-444d-ad31-992851eac876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\n",
      "Best Params: {'n_neighbors': 3}\n",
      "Accuracy: 100.0\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(name)\n",
    "print(\"Best Params:\", clf.best_params_)\n",
    "print(\"Accuracy:\", accuracy * 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f1d5dc-ab6d-4ff6-b646-8330847cc5fd",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e421e509-7760-4c37-b89b-972216483ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "Mean Squared Error:  0.03723364456197502\n"
     ]
    }
   ],
   "source": [
    "linear_reg = LinearRegression()\n",
    "linear_reg.fit(X_train, y_train)\n",
    "y_pred_lr = linear_reg.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred_lr)\n",
    "print('Linear Regression:')\n",
    "print('Mean Squared Error: ', mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30c5e94-783c-49b9-91c0-9b114ab8a429",
   "metadata": {},
   "source": [
    "### My analysis on Perfomance of Models on Iris Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46a4a52-9393-4235-8383-6eb572b6931e",
   "metadata": {},
   "source": [
    "### . KNN achieved perfect accuracy on the test set with the best parameter being 3 neighbors. \n",
    "### . This indicates that KNN is highly effective for iris dataset when configured with n_neighbors hyperparameter set to 3.\n",
    "### . Linear Regression shows a low Mean Squared Error i.e 0.0372..., which suggests that the model performs well in terms of prediction accuracy.\n",
    "### . Although Linear Regression is typically more suited for regression tasks rather than classification."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
