{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "303d6d78-21f7-44db-8da6-db180cc628de",
   "metadata": {},
   "source": [
    "# Task 30-> Some preprocessing Using scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a91a5d-2ecd-4a7a-8017-c7e9d7005cad",
   "metadata": {},
   "source": [
    "#######\n",
    "Preprocessing is a crucial step in preparing your data for machine learning models. Using scikit-learn, \n",
    "you can scale features with StandardScaler, encode categorical variables with OneHotEncoder, and impute \n",
    "missing values with SimpleImputer. For example, numerical features can be standardized to have zero mean\n",
    "and unit variance, while categorical features can be converted into binary variables. Once \n",
    "preprocessing is complete, you can apply various machine learning models from sklearn like Linear \n",
    "Regression, Logistic Regression, and Random Forest. To optimize these models, perform hyperparameter\n",
    "tuning using techniques such as Grid Search and Random Search. Apply these models to your datasets and \n",
    "note down the results based on the techniques you applied to evaluate their performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d0131a-9f25-43ea-81f1-bf3527f886eb",
   "metadata": {},
   "source": [
    "### importing necessary libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1a784ef-0578-4371-83c9-8203b195b6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "\n",
    "\n",
    "file_path = r'C:\\Users\\Huawei\\Desktop\\Titanic-Dataset.csv'\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93143ebe-05da-4021-85da-d9b0e671cfa8",
   "metadata": {},
   "source": [
    "### features and target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9ef01c5-f353-4271-9c74-0c4b96d15ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.drop(columns=['Survived'])\n",
    "target = data['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0295b6-9d6e-4127-b3a5-8f00216cde06",
   "metadata": {},
   "source": [
    "### numerical and categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f3c1f93-351a-4628-a9a5-f7b038b24a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = features.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_cols = features.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ad4091-e154-45be-8b7e-4b9d728a3a43",
   "metadata": {},
   "source": [
    "### Separate numerical and categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5be98a63-f84c-4830-a90b-dcdb5a19432c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numerical = features[numerical_cols]\n",
    "X_categorical = features[categorical_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247c2b8c-ff62-4bb6-948a-4aa32c3dea6e",
   "metadata": {},
   "source": [
    "### Initialize the imputer and scaler for numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f19b833a-c5e4-4a75-acff-6d6da5825402",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer_num = SimpleImputer(strategy='mean')#missing values will be filled with mean of the respective column\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9367d0d-f006-4cec-85dd-077a0bce7ae4",
   "metadata": {},
   "source": [
    "### Fit and transform the numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c255df52-db4b-4c8b-9774-22736a4335b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numerical_imputed = imputer_num.fit_transform(X_numerical)\n",
    "X_numerical_scaled = scaler.fit_transform(X_numerical_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2604419-e5a1-47a5-81a2-8532d6c7b3bc",
   "metadata": {},
   "source": [
    "### Initialize the imputer and encoder for categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4787a97-f82f-43a0-951a-83faf24e0732",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer_cat = SimpleImputer(strategy='most_frequent')#missing values will be filled with mode(most_frequent) of the respective column\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)#handle_unknown='ignore' means ignore any unknown categories \n",
    "#sparse_output=False means encoded data is returned as regular array rather than in such a format that saves space by only storing non_zero values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f0390b-3eb5-4f7b-9755-542e8556c754",
   "metadata": {},
   "source": [
    "### Fit and transform the categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e8d26e9-8ba6-415f-bde9-dba0745569fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_categorical_imputed = imputer_cat.fit_transform(X_categorical)\n",
    "X_categorical_encoded = encoder.fit_transform(X_categorical_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d9e2c5-5336-4a28-9df6-cebde7bb7161",
   "metadata": {},
   "source": [
    "### Combine numerical and categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20ea92aa-016a-4261-bbc0-e55eb9d4cb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_preprocessed = np.hstack((X_numerical_scaled, X_categorical_encoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0723f836-889d-4b81-bd33-65e510d2e594",
   "metadata": {},
   "source": [
    "### Split data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d3a538d-a76f-41ba-8f76-f80620929628",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340b8b15-ffe9-488e-a2b3-9ec5d2b46f41",
   "metadata": {},
   "source": [
    "### Train a RandomForest model for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5356c72f-d909-4f92-ae9b-f6dd198badd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47936408-2d72-4a9d-bcb4-d8ff289fc9f9",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning for RandomForest using grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0dcbccc7-6f58-4e12-b869-e14e07604645",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters from RandomForest Grid Search:  {'max_depth': None, 'n_estimators': 50}\n",
      "Best accuracy from RandomForest Grid Search:  75.0\n"
     ]
    }
   ],
   "source": [
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30]\n",
    "}\n",
    "grid_search_rf = GridSearchCV(model_rf, param_grid_rf, cv=4, scoring='accuracy')\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "print(\"Best parameters from RandomForest Grid Search: \", grid_search_rf.best_params_)\n",
    "print(\"Best accuracy from RandomForest Grid Search: \", grid_search_rf.best_score_*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378ca5bd-8f98-48b2-a4d9-ada9a4ea8237",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning for RandomForest using random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfcd41f7-3a39-492e-b1e9-e1a073918141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters from RandomForest Random Search:  {'max_depth': 20, 'n_estimators': 142}\n",
      "Best accuracy from RandomForest Random Search:  87.5\n"
     ]
    }
   ],
   "source": [
    "model_rf = RandomForestClassifier(random_state=42)\n",
    "param_dist_rf = {\n",
    "    'n_estimators': randint(50, 201), \n",
    "    'max_depth': [None, 10, 20, 30]\n",
    "}\n",
    "random_search_rf = RandomizedSearchCV(estimator=model_rf, param_distributions=param_dist_rf, n_iter=10, cv=4, scoring='accuracy', random_state=42, n_jobs=-1)\n",
    "random_search_rf.fit(X_train, y_train)\n",
    "print(\"Best parameters from RandomForest Random Search: \", random_search_rf.best_params_)\n",
    "print(\"Best accuracy from RandomForest Random Search: \", random_search_rf.best_score_ * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd28bd8a-7552-4ce5-9119-a61a949d67c6",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning for random forest model evaluation\n",
    "### . The RandomForest model from Random Search, with parameters {'max_depth': 20, 'n_estimators': 142}, achieved a higher accuracy of 87.5% compared to the Grid Search model's accuracy of 75%. \n",
    "### . This indicates that the Random Search approach with its parameter tuning performed significantly better due to better optimization of hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65386c59-a762-4d6f-934c-c05127acd28a",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning for Logistic Regression using grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d77f2a9f-f3d9-4081-9e33-3e7d21911e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters from Grid Search: {'C': 0.01, 'solver': 'liblinear'}\n",
      "Best accuracy from Grid Search: 62.50\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],  \n",
    "    'solver': ['liblinear', 'lbfgs'],  \n",
    "}\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=4, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best parameters from Grid Search:\", grid_search.best_params_)\n",
    "print(\"Best accuracy from Grid Search: {:.2f}\".format(grid_search.best_score_ * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b60b10-497e-493a-899f-2928d732b915",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning for Logistic Regression using random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4aa9564b-e42f-4823-8501-1cc319602022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters from Randomized Search: {'C': 37.464011884736244, 'solver': 'liblinear'}\n",
      "Best accuracy from Randomized Search: 62.50\n"
     ]
    }
   ],
   "source": [
    "param_dist = {\n",
    "    'C': uniform(0.01, 100), \n",
    "    'solver': ['liblinear', 'lbfgs'],  \n",
    "}\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=10, cv=4, scoring='accuracy', random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "print(\"Best parameters from Randomized Search:\", random_search.best_params_)\n",
    "print(\"Best accuracy from Randomized Search: {:.2f}\".format(random_search.best_score_ * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a363ecc5-b440-45df-9515-3fdfc4f0d151",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning for Logistic Regression model evaluation\n",
    "### . Both Grid Search and Randomized Search achieved the same accuracy of 62.5%. Despite the Randomized Search identifying a higher value for C(i.e Regularization Strength) (37.46).\n",
    "### . It did not improve the model's performance over the Grid Search, suggesting that the accuracy is not significantly influenced by the choice of hyperparameters in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e16d502-bc00-49d3-a472-7a6cc012e8f9",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning for Linear Regression using grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "508e76a3-2a82-41f1-9ad8-95f28900c81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Mean Squared Error (Grid Search):  2.14589065023884\n",
      "Linear Regression R^2 Score (Grid Search):  0.0\n"
     ]
    }
   ],
   "source": [
    "#Grid Search is not applicable for LinearRegression as it has no hyperparameters, For demonstration purposes, I proceed without parameters\n",
    "\n",
    "linear_model = LinearRegression()\n",
    "grid_search = GridSearchCV(estimator=linear_model, param_grid={}, cv=4, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_model_grid = grid_search.best_estimator_\n",
    "y_pred_grid = best_model_grid.predict(X_test)\n",
    "mse_grid = mean_squared_error(y_test, y_pred_grid)\n",
    "r2_grid = r2_score(y_test, y_pred_grid)\n",
    "print(\"Linear Regression Mean Squared Error (Grid Search): \", mse_grid*100)\n",
    "print(\"Linear Regression R^2 Score (Grid Search): \", r2_grid*100)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393e1eb1-532d-4fd3-b315-52e711d2253e",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning for Linear Regression using random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8010ee0-b47f-434b-93e3-89768a6915c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Mean Squared Error (Random Search):  2.14589065023884\n",
      "Linear Regression R^2 Score (Random Search):  0.0\n"
     ]
    }
   ],
   "source": [
    "# Random Search is not applicable for LinearRegression as it has no hyperparameters, For demonstration purposes, I proceed without parameters\n",
    "\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=linear_model, param_distributions={}, n_iter=1, cv=4, scoring='neg_mean_squared_error', random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "best_model_random = random_search.best_estimator_\n",
    "y_pred_random = best_model_random.predict(X_test)\n",
    "mse_random = mean_squared_error(y_test, y_pred_random)\n",
    "r2_random = r2_score(y_test, y_pred_random)\n",
    "print(\"Linear Regression Mean Squared Error (Random Search): \", mse_random*100)\n",
    "print(\"Linear Regression R^2 Score (Random Search): \", r2_random*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a570585a-56d2-48ec-b0ca-6ec5e0ba55ce",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning for Linear Regression model evaluation\n",
    "### . Both Grid Search and Randomized Search for Linear Regression produced identical Mean Squared Error (MSE) and R² scores i.e MSE: 2.146 and R²: 0.0 . \n",
    "### . This indicates that neither hyperparameter search method improved the model's performance. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
