{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2efb1b4b-82d1-49b4-b8d7-52167cfae229",
   "metadata": {},
   "source": [
    "# Task 28-> Exploring Cross-Validation, Overfitting, and Underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65472b7-48be-4b89-b394-0e63036a40fc",
   "metadata": {},
   "source": [
    "#######\n",
    "Cross-Validation\n",
    "Cross-validation is a technique used to assess the performance and generalization ability of a model by partitioning the dataset into multiple subsets or folds.\n",
    "Overfitting\n",
    "Overfitting occurs when a model learns the details and noise in the training data to the extent that it negatively impacts its performance on new, unseen data. Characteristics include:\n",
    "Underfitting\n",
    "Underfitting occurs when a model is too simple to capture the underlying patterns in the data. \n",
    "Characteristics include:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7e160c-1635-49d1-9c5f-b727e91728c8",
   "metadata": {},
   "source": [
    "### Import necessary libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fc109ae-10ea-4688-a682-143e688fffbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "file_path = r'C:\\Users\\Huawei\\Desktop\\Titanic-Dataset.csv'\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1c6f82-73cb-4361-8546-b836fd77a968",
   "metadata": {},
   "source": [
    "### Split data into features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4de0186-341b-4432-943b-269c907d0bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Sex'] = LabelEncoder().fit_transform(data['Sex'])  # Convert 'Sex' to numeric to remove error cannot convert string to float 'male'\n",
    "\n",
    "# Split data into features and target\n",
    "X = data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']]\n",
    "y = data['Survived']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687c6530-a8de-4b19-9b44-7a5f406f311e",
   "metadata": {},
   "source": [
    "### Split data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27335597-880c-4063-bae0-880021fd6edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec69b00-e4dd-4565-8917-37922175c301",
   "metadata": {},
   "source": [
    "### Initialize models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d0132e8-f116-4a26-8dc0-2fb1be2ee6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "tree_model = DecisionTreeClassifier(max_depth=2) # Simple model (underfitting)\n",
    "complex_tree_model = DecisionTreeClassifier(max_depth=10) # Complex model (overfitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d89900-e153-4ce5-b7d2-c6dad598a71d",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6709dc1-cc31-4608-beeb-0d806e266760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y):\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b9ea89-28b5-447a-8c7c-455c697c03ee",
   "metadata": {},
   "source": [
    "### Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac1b3b3a-2fa0-4e8d-ab26-9ae01cc4aff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Model CV Score: 66.0\n",
      "Simple Tree Model CV Score: 78.0\n",
      "Complex Tree Model CV Score: 86.99999999999999\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Model CV Score:\", evaluate_model(logistic_model, X_train, y_train)*100)\n",
    "print(\"Simple Tree Model CV Score:\", evaluate_model(tree_model, X_train, y_train)*100)\n",
    "print(\"Complex Tree Model CV Score:\", evaluate_model(complex_tree_model, X_train, y_train)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8cc16d-44ba-431d-ac5c-06ec5e2ee845",
   "metadata": {},
   "source": [
    "### My Understanding Of the CV Score\n",
    "### . As CV(Cross Validation) score tells us that how well the model will perform on new/unseen data. \n",
    "### . So logistic regression model correctly predicts the survival status about 66% of the time, which is relatively low as compare to simple tree model which have cv score of 78%.\n",
    "### . Complex tree model has the highest CV Score among all models used with approx 87% of the correct prediction about survival status."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010903b4-6b40-40c7-9052-298618071e67",
   "metadata": {},
   "source": [
    "### My understanding Of Overfitting\n",
    "### . Overfitting occurs when a model learns irrrelevant data during training to the extent that it negatively impacts its performance on new, unseen data. \n",
    "### . When there is less training data, model learns irreleveant data rather than general pattrens which results to lower accuracy on unseen data despite having high accuracy on training data.\n",
    "### . In above code in complex_tree_model, max_depth(no. of levels tree can have)=10, if I increase it further, it will capture more complex pattrens but can lead to overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448dd50e-223f-4c2a-b232-177acb598c24",
   "metadata": {},
   "source": [
    "### My understanding of Underfitting\n",
    "### . Underfitting happens when a model is too basic to understand the patterns in the data.\n",
    "### . As a result, it performs poorly on both the training data and new data. Thus It leads to lower accuracy.\n",
    "### . In above code in tree model, max_depth=2, so decreasing max_depth further simplifies the model, thus reducing the risk of overfitting but it can lead to underfitting if too low."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
