{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00b045d4-aaf7-4f65-b610-1373c1f0673d",
   "metadata": {},
   "source": [
    "# Task 25-> Logistic Regression from scratch\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4ee0ac-5bdd-46df-b849-65082af3e0e8",
   "metadata": {},
   "source": [
    "######## Logistic Regression from scratch involves building a classification model by implementing the logistic \n",
    "function and optimization algorithm manually. You start with defining the sigmoid function to model \n",
    "probabilities, then use a cost function (like cross-entropy) to measure prediction error. \n",
    "Optimization, typically using gradient descent, adjusts model weights to minimize the cost function and \n",
    "improve accuracy. This process helps you understand the core mechanics of logistic regression beyond \n",
    "using built-in libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ebfc41-5b26-4808-9e18-708e8bcf67f6",
   "metadata": {},
   "source": [
    "# import necessary Libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "68451701-9068-4cef-9f3f-1c1da9bf64ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "file_path = r'C:\\Users\\Huawei\\Desktop\\anemia.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7256a9e-9423-4974-a81f-4cf62245fdd5",
   "metadata": {},
   "source": [
    "#define features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3c3374ca-8b9f-4a5f-b32e-88cc0cd881c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['Gender', 'Hemoglobin', 'MCH', 'MCHC', 'MCV']].values\n",
    "y = data['Result'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7878cbee-dde8-4838-95c3-4ea5949451e7",
   "metadata": {},
   "source": [
    "# Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a65e693-b4da-4c4b-b65b-ccc4a0d12299",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ec36d0-fce3-4585-a394-6afcc044d715",
   "metadata": {},
   "source": [
    "# Sigmoid function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2dfcb834-5c38-483a-883e-da4c2167e73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43315c3-a419-4299-aac9-e613b06c266a",
   "metadata": {},
   "source": [
    "# Cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1d5c4bc7-34d2-4caf-b62c-1d8eb961c8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(X, y, weights):\n",
    "    m = len(y)\n",
    "    h = sigmoid(np.dot(X, weights))\n",
    "    cost = -1/m * (np.dot(y, np.log(h)) + np.dot((1 - y), np.log(1 - h)))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610f27ba-8a5f-4bb9-aa42-c90c16f862c8",
   "metadata": {},
   "source": [
    "# Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4d563f3c-9f80-4792-9f59-43c63d3d021d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, weights, learning_rate, iterations):\n",
    "    m = len(y)\n",
    "    for i in range(iterations):\n",
    "        h = sigmoid(np.dot(X, weights))\n",
    "        gradient = np.dot(X.T, (h - y)) / m\n",
    "        weights -= learning_rate * gradient\n",
    "        if i % 100 == 0:\n",
    "            cost = compute_cost(X, y, weights)\n",
    "            print(\"Iteration\", i, \"Cost\", cost)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fadfd12-56a9-4b1d-b5a8-73f172383b60",
   "metadata": {},
   "source": [
    "# Logistic regression function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a5f922ee-3434-4907-bac5-740f89f20cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(X_train, y_train, learning_rate=0.01, iterations=1000):\n",
    "    weights = np.zeros(X_train.shape[1])\n",
    "    weights = gradient_descent(X_train, y_train, weights, learning_rate, iterations)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3748e430-183f-4c6d-8a10-e0749e2fa537",
   "metadata": {},
   "source": [
    "# Prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ea1b81e8-324f-469a-8a73-9dd8053180ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, weights, threshold=0.5):\n",
    "    probabilities = sigmoid(np.dot(X, weights))\n",
    "    return probabilities >= threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7015a9-6d98-403d-8242-80b346ae6c50",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4d32f229-d99e-46c0-b131-ce0b86f668b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Cost 5.0718687456441565\n",
      "Iteration 100: Cost 2.6206888815654934\n",
      "Iteration 200: Cost 15.217663043906294\n",
      "Iteration 300: Cost 4.821840176942691\n",
      "Iteration 400: Cost 7.926357343821111\n",
      "Iteration 500: Cost 11.485062401245026\n",
      "Iteration 600: Cost 1.588197615433473\n",
      "Iteration 700: Cost 6.179175037535954\n",
      "Iteration 800: Cost 1.5247849371301763\n",
      "Iteration 900: Cost 10.832518862343886\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weights = logistic_regression(X_train, y_train)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba15aab-4b3e-4a7e-bb77-b107bd4fcb05",
   "metadata": {},
   "source": [
    "# Prediction on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "736326c0-639f-4dac-b45f-1646874522c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [ True  True False False]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = predict(X_test, weights)\n",
    "print(\"Predictions:\", predictions)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414c0a51-e738-41b3-9c5e-5878f0d93860",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "85d79a13-8ddd-41a6-9098-f8ac2dda3570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.0\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.mean(predictions == y_test)#calculates the percentage of correct predictions by comapring the model's prediction to actual values\n",
    "print(\"Accuracy:\", accuracy * 100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
